 
import numpy as np 
import matplotlib.pyplot as plt 
import math
import seaborn as sbn
import copy
import random as rnd

def polynomial_kernel(x,y,p = 3):
  return (1+np.dot(x,y))**p

def gaussian_kernel(x, y, sigma=5.0):
    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))

def generatedataset(size,mean1,cov1,mean2,cov2): 
  np.random.seed() 
  n = int(size/2)
  Z = np.ones(n)*-1
  C = np.random.multivariate_normal(mean1,cov1,size=n)
  X = np.c_[C,Z]
  O = np.ones(n)
  c = np.random.multivariate_normal(mean2,cov2,size=n)
  Y = np.c_[c,O] 
  dataset = np.concatenate((X,Y),axis=0)
  np.random.shuffle(dataset)
  #return dataset
  l = []
  for i in range(len(dataset)):
    if (dataset[i][0]-1)**2 + (dataset[i][1]-4)**2 < 4:
      dataset[i][2] = -1.0
    elif (dataset[i][0]-1)**2 + (dataset[i][1]-4)**2 > 4:
      dataset[i][2] = 1.0
    else:
      l.append(i)
  
  ds = np.delete(dataset,l,0)

  return ds

def splitdataset(dataset):
  n = len(dataset)
  x = int(n/10)
  learnset = dataset[0:n-x]
  testset = dataset[n-x:n]
  return learnset,testset

def kernelperceptron(learnset,n):
  a = np.zeros(len(learnset))
  b = 0
  misclassified = []
  data = learnset[:,:-1]
  labels = learnset[:,-1]
  #print(data)
  #print(labels)
  for epoch in range(n):
    miss = 0
    for i in range(len(data)):
      s = 0
      x = data[i]
      for j in range(len(data)):
        y = data[j]
        s = s + a[j]*labels[j]*gaussian_kernel(y,x)
      if labels[i]*(s+b) <= 0:
        a[i] = a[i] + 1
        b = b + labels[i]
        miss = miss+1
    misclassified.append(miss)
    #print(a)
  return a,b,labels,misclassified

def predict(a,b,labels,testset,learnset):
  data = testset[:,:-1]
  data1 = learnset[:,:-1]
  lbl = []
  for i in range(len(data)):
    s = 0
    x = data[i]
    for j in range(len(data1)):
      y = data1[j]
      s = s + a[j]*labels[j]*gaussian_kernel(y,x)
    lbl.append(np.sign(s+b))
  sbn.scatterplot(data[:,0],data[:,1],hue = lbl,palette = ['red','blue']).set_title('Prediction')
  plt.show()
  return lbl

def Error(testset,lst):
  c = 0
  n = len(lst)
  for i in range(n):
    if testset[i][2] != lst[i]:
      c = c+1
  return c*100/n;

size = 400
mean1 = [1,4]
mean2 = [1,4]
cov1 = [[5,0],[0,5]]
cov2 = [[5,0],[0,10]]
dataset = generatedataset(size,mean1,cov1,mean2,cov2)
#print(dataset)
sbn.scatterplot(dataset[:,0],dataset[:,1],hue = dataset[:,2],palette = ['red','blue']).set_title('Generated Dataset')
plt.show()

learnset,testset = splitdataset(dataset)
sbn.scatterplot(learnset[:,0],learnset[:,1],hue = learnset[:,2],palette = ['red','blue']).set_title('Learning Dataset')
plt.show()
sbn.scatterplot(testset[:,0],testset[:,1],hue = testset[:,2],palette = ['red','blue']).set_title('Actual Testing Set')
plt.show()

n = 100
a,b,labels,misclassified = kernelperceptron(learnset,n)
epochs = np.arange(n)
plt.plot(epochs,misclassified)
plt.xlabel('Iterations')
plt.ylabel('Misclassifications')
plt.show()

lst = predict(a,b,labels,testset,learnset)
print("Error in prediction : "+str(Error(testset,lst))+"%")